{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class model():\n",
    "    def __init__(self,profile):\n",
    "        self.x = tf.placeholder(tf.float32, [None, 784])\n",
    "        self.y = tf.placeholder(tf.int32,[None,10])\n",
    "        self.profile = profile\n",
    "\n",
    "        self.W1 = tf.get_variable(initializer=tf.random_uniform([784, 100],-0.1,0.1),name=\"W1\")\n",
    "        self.b1 = tf.get_variable(initializer=tf.random_uniform([100],-0.1,0.1),name=\"b1\")\n",
    "        self.W2 = tf.get_variable(initializer=tf.random_uniform([100, 100],-0.1,0.1),name=\"W2\")\n",
    "        self.b2 = tf.get_variable(initializer=tf.random_uniform([100],-0.1,0.1),name=\"b2\")\n",
    "        self.W3 = tf.get_variable(initializer=tf.random_uniform([100, 10],-0.1,0.1),name=\"W3\")\n",
    "        self.b3 = tf.get_variable(initializer=tf.random_uniform([10],-0.1,0.1),name=\"b3\")\n",
    "        \n",
    "        def half_exp(n,k=1,dtype='float32'):\n",
    "            n_ones = int(n/2)\n",
    "            n_other = n - int(n/2)\n",
    "            return np.append(np.ones(n_ones,dtype=dtype),np.exp((1-k)*np.arange(n_other),dtype=dtype))\n",
    "\n",
    "        if profile == \"linear\":\n",
    "            self.r1 = tf.get_variable(initializer=np.linspace(1,0,num=784,endpoint=False,dtype='float32'),name=\"r1\",dtype='float32')\n",
    "            self.r2 = tf.get_variable(initializer=np.linspace(1,0,num=100,endpoint=False,dtype='float32'),name=\"r2\",dtype='float32')\n",
    "            self.r3 = tf.get_variable(initializer=np.linspace(1,0,num=100,endpoint=False,dtype='float32') ,name=\"r3\",dtype='float32')\n",
    "        elif profile == \"all-one\":\n",
    "            self.r1 = tf.get_variable(initializer=np.ones(784,dtype='float32'),name=\"r1\",dtype='float32')\n",
    "            self.r2 = tf.get_variable(initializer=np.ones(100,dtype='float32'),name=\"r2\",dtype='float32')\n",
    "            self.r3 = tf.get_variable(initializer=np.ones(100,dtype='float32'),name=\"r3\",dtype='float32')\n",
    "        elif profile == \"half-exp\":\n",
    "            self.r1 = tf.get_variable(initializer=half_exp(784,2),name=\"r1\",dtype='float32')\n",
    "            self.r2 = tf.get_variable(initializer=half_exp(100,2),name=\"r2\",dtype='float32')\n",
    "            self.r3 = tf.get_variable(initializer=half_exp(100,2),name=\"r3\",dtype='float32')\n",
    "        else:\n",
    "            self.r1 = tf.get_variable(initializer=np.array(1.0/(np.arange(784)+1),dtype='float32'),name=\"r1\",dtype='float32')\n",
    "            self.r2 = tf.get_variable(initializer=np.array(1.0/(np.arange(100)+1),dtype='float32'),name=\"r2\",dtype='float32')\n",
    "            self.r3 = tf.get_variable(initializer=np.array(1.0/(np.arange(100)+1),dtype='float32') ,name=\"r3\",dtype='float32')\n",
    "        self.learning_rate = 0.001\n",
    "        # calculate r1*(W1*x)+b\n",
    "        #z1 = tf.add(tf.multiply(self.r1,tf.matmul(self.x,self.W1)),self.b1)\n",
    "        #z1 = tf.add(tf.matmul(tf.multiply(self.r1,self.x),self.W1),self.b1)\n",
    "        z1 = tf.add(tf.matmul(self.x,self.W1),self.b1)\n",
    "        y1 = tf.nn.relu(z1)\n",
    "        z2 = tf.add(tf.matmul(tf.multiply(self.r2,y1),self.W2),self.b2)\n",
    "        #z2 = tf.add(tf.multiply(self.r2,tf.matmul(y1,self.W2)),self.b2)\n",
    "        y2 = tf.nn.relu(z2)\n",
    "\n",
    "        #self.logits = tf.add(tf.multiply(self.r3,tf.matmul(y2,self.W3)),self.b3)\n",
    "        #self.logits = tf.add(tf.matmul(tf.multiply(self.r3,y2),self.W3),self.b3)\n",
    "        self.logits = tf.add(tf.matmul(y2,self.W3),self.b3)\n",
    "        self.probs = tf.nn.softmax(self.logits)\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=self.logits,labels=self.y)\n",
    "        self.loss = tf.reduce_mean(cross_entropy)\n",
    "        \n",
    "        correct_prediction = tf.equal(tf.argmax(self.probs,1), tf.argmax(self.y,1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        tvars_trainable = tf.trainable_variables()\n",
    "        self.gamma_vars = [self.r1,self.r2,self.r3]\n",
    "        \n",
    "        for rm in self.gamma_vars:\n",
    "            tvars_trainable.remove(rm)\n",
    "            print('%s is not trainable.'% rm)\n",
    "        self.tvars_trainable = tvars_trainable\n",
    "\n",
    "        tvars = tf.trainable_variables()\n",
    "        self.tvars = tvars\n",
    "        self.opt = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        self.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss,var_list=self.tvars_trainable)\n",
    "        self.train_op_gamma = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss,var_list=self.gamma_vars)\n",
    "        \n",
    "    def train(self,sess,config,gamma_trainable=False,reuse=False,verbose=True):\n",
    "        self.learning_rate = config[\"learning_rate\"]\n",
    "#         # calculate r1*(W1*x)+b\n",
    "#         #z1 = tf.add(tf.multiply(self.r1,tf.matmul(self.x,self.W1)),self.b1)\n",
    "#         #z1 = tf.add(tf.matmul(tf.multiply(self.r1,self.x),self.W1),self.b1)\n",
    "#         z1 = tf.add(tf.matmul(self.x,self.W1),self.b1)\n",
    "#         y1 = tf.nn.relu(z1)\n",
    "#         z2 = tf.add(tf.matmul(tf.multiply(self.r2,y1),self.W2),self.b2)\n",
    "#         #z2 = tf.add(tf.multiply(self.r2,tf.matmul(y1,self.W2)),self.b2)\n",
    "#         y2 = tf.nn.relu(z2)\n",
    "\n",
    "#         #self.logits = tf.add(tf.multiply(self.r3,tf.matmul(y2,self.W3)),self.b3)\n",
    "#         #self.logits = tf.add(tf.matmul(tf.multiply(self.r3,y2),self.W3),self.b3)\n",
    "#         self.logits = tf.add(tf.matmul(y2,self.W3),self.b3)\n",
    "#         self.probs = tf.nn.softmax(self.logits)\n",
    "#         cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=self.logits,labels=self.y)\n",
    "#         self.loss = tf.reduce_mean(cross_entropy)\n",
    "        \n",
    "#         correct_prediction = tf.equal(tf.argmax(self.probs,1), tf.argmax(self.y,1))\n",
    "#         self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "#         tvars_trainable = tf.trainable_variables()\n",
    "#         self.gamma_vars = [self.r1,self.r2,self.r3]\n",
    "        \n",
    "#         if gamma_trainable:\n",
    "#             print('Only gamma(s) are trainable.')\n",
    "#             self.tvars_trainable = self.gamma_vars\n",
    "#         else:\n",
    "#             for rm in self.gamma_vars:\n",
    "#                 tvars_trainable.remove(rm)\n",
    "#                 print('%s is not trainable.'% rm)\n",
    "#             self.tvars_trainable = tvars_trainable\n",
    "\n",
    "#         tvars = tf.trainable_variables()\n",
    "#         self.tvars = tvars\n",
    "#         self.opt = tf.train.AdamOptimizer(self.learning_rate)\n",
    "#         self.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss,var_list=self.tvars_trainable)\n",
    "#         self.train_op_gamma = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss,var_list=self.gamma_vars)\n",
    "        \n",
    "        if not reuse:\n",
    "            for v in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES):\n",
    "                sess.run(v.initializer)\n",
    "            print(\"Initialized.\")\n",
    "\n",
    "        epochs = config['epochs']\n",
    "        batch_per_epoch = config['batch_per_epoch']\n",
    "        batch_size = config['batch_size']\n",
    "        save_dir = config['save_dir']\n",
    "        mnist = config['mnist']\n",
    "\n",
    "        #saver = tf.train.Saver(tf.global_variables())\n",
    "        val_loss_per_epoch = []\n",
    "        val_accu_per_epoch = []\n",
    "        loss_per_epoch = []\n",
    "        accu_per_epoch = []\n",
    "        for epoch in range(0,epochs):\n",
    "            start_time = time.time()\n",
    "            train_loss = []\n",
    "            train_accu = []\n",
    "            for batch in range(0,batch_per_epoch):\n",
    "                batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                if gamma_trainable:\n",
    "                    _,loss, accu = sess.run([self.train_op_gamma, self.loss, self.accuracy], \n",
    "                                            feed_dict = {self.x:batch_x, self.y: batch_y})\n",
    "                else:\n",
    "                    _,loss, accu = sess.run([self.train_op, self.loss, self.accuracy], \n",
    "                                            feed_dict = {self.x:batch_x, self.y: batch_y})\n",
    "                train_loss.append(loss)\n",
    "                train_accu.append(accu)\n",
    "            loss_per_epoch.append(np.mean(train_loss))\n",
    "            accu_per_epoch.append(np.mean(train_accu))\n",
    "            \n",
    "            # test after one epoch\n",
    "            val_loss , probs, val_accu = sess.run([self.loss,self.probs,self.accuracy],feed_dict={self.x:mnist.test.images, self.y:mnist.test.labels})\n",
    "            val_loss_per_epoch.append(val_loss)\n",
    "            val_accu_per_epoch.append(val_accu)\n",
    "            if verbose:\n",
    "                print(\" epoch: %3d \\t time: %3f \\t loss: %3f \\t val_loss: %3f \\t accu: %3f \\t val_accu: %3f\"% \n",
    "                  (epoch,time.time() - start_time,np.mean(train_loss), val_loss, np.mean(train_accu), val_accu))\n",
    "        return({'loss':loss_per_epoch, 'val_loss':val_loss_per_epoch,'accu':accu_per_epoch,'val_accu':val_accu_per_epoch})\n",
    "    \n",
    "    def predict(self,sess,config,idp,scope):\n",
    "        with tf.variable_scope(scope):\n",
    "            # use variable t to control the on/off of neurons\n",
    "            n_ones = int(784 * idp)\n",
    "            n_zeros = 784 - n_ones\n",
    "            t1 = tf.get_variable(initializer=np.append(np.ones(n_ones,dtype='float32'),np.zeros(n_zeros,dtype='float32')),name=\"t1\",dtype='float32')\n",
    "\n",
    "            n_ones = int(100 * idp)\n",
    "            n_zeros = 100 - n_ones\n",
    "            t2 = tf.get_variable(initializer=np.append(np.ones(n_ones,dtype='float32'),np.zeros(n_zeros,dtype='float32')),name=\"t2\",dtype='float32')\n",
    "\n",
    "            n_ones = int(100 * idp)\n",
    "            n_zeros = 100 - n_ones\n",
    "            t3 = tf.get_variable(initializer=np.append(np.ones(n_ones,dtype='float32'),np.zeros(n_zeros,dtype='float32')),name=\"t3\",dtype='float32')\n",
    "\n",
    "            p1 = tf.get_variable(initializer=tf.multiply(self.r1,t1),name=\"p1\")\n",
    "            p2 = tf.get_variable(initializer=tf.multiply(self.r2,t2),name=\"p2\")\n",
    "            p3 = tf.get_variable(initializer=tf.multiply(self.r3,t3),name=\"p3\")\n",
    "\n",
    "            for v in [t1,t2,t3,p1,p2,p3]:\n",
    "                sess.run(v.initializer)\n",
    "            print(\"Running IDP mechanism {:.0f}%\".format(idp*100),end='\\r')\n",
    "            \n",
    "            #sess.run(tf.pack([tf.is_variable_initialized(v) for v in [t1,t2,t3,p1,p2,p3]]))\n",
    "            #print(\"Initialized IDP mechanism.\")\n",
    "\n",
    "            #z1 = tf.add(tf.multiply(self.r1,tf.matmul(self.x,self.W1)),self.b1)\n",
    "            #z1 = tf.add(tf.matmul(tf.multiply(self.r1,self.x),self.W1),self.b1)\n",
    "            z1 = tf.add(tf.matmul(self.x,self.W1),self.b1)\n",
    "            y1 = tf.nn.relu(z1)\n",
    "            # IDP on layer 2\n",
    "            #z2 = tf.add(tf.multiply(p2,tf.matmul(y1,self.W2)),self.b2)\n",
    "            z2 = tf.add(tf.matmul(tf.multiply(p2,y1),self.W2),self.b2)\n",
    "            y2 = tf.nn.relu(z2)\n",
    "            #logits = tf.add(tf.multiply(self.r3,tf.matmul(y2,self.W3)),self.b3)\n",
    "            #logits = tf.add(tf.matmul(tf.multiply(self.r3,y2),self.W3),self.b3)\n",
    "            logits = tf.add(tf.matmul(y2,self.W3),self.b3)\n",
    "            self.pred_probs = tf.nn.softmax(logits)\n",
    "\n",
    "            mnist = config['mnist']\n",
    "            pred_probs = sess.run([self.pred_probs],\n",
    "                                  feed_dict={self.x:mnist.test.images, self.y:mnist.test.labels})\n",
    "            return(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "profile_test = [\"all-one\",\"linear\",\"harmonic\",\"half-exp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "counter = counter + 1\n",
    "for profile in profile_test:\n",
    "    print(profile)\n",
    "    with tf.variable_scope(profile+str(counter)):\n",
    "        model_test = model(profile=profile)\n",
    "        save_dir = \"~/IDP/output/1_\"\n",
    "        epochs = 40\n",
    "        batch_per_epoch = 200\n",
    "        batch_size = 28\n",
    "        learning_rate = 0.001\n",
    "        config = {'epochs': epochs,\n",
    "                  'batch_per_epoch': batch_per_epoch,\n",
    "                  'batch_size': batch_size,\n",
    "                  'learning_rate': learning_rate,\n",
    "                  'save_dir': save_dir,\n",
    "                  'log_file': save_dir+profile+\"_log.csv\",\n",
    "                  'result_file': save_dir+profile+\"_result.csv\",\n",
    "                  'mnist': mnist}\n",
    "        with tf.Session() as sess:\n",
    "            log = model_test.train(sess=sess,config=config,gamma_trainable=False,verbose=False)\n",
    "            log = pd.DataFrame.from_dict(log)\n",
    "            log.to_csv(config['log_file'],index=None)\n",
    "            print(log)\n",
    "            \n",
    "            true_lab = [np.argmax(ite) for ite in mnist.test.labels]\n",
    "            profile_arr = []\n",
    "            idp_arr = []\n",
    "            accu_arr = []\n",
    "            for idp in np.arange(0.1,1.05,0.05):  \n",
    "                probs = model_test.predict(sess=sess,config=config,idp=idp,scope='i'+str(int(idp*100)))\n",
    "                pred_lab = [np.argmax(ite) for ite in probs[0]]\n",
    "                accu = accuracy_score(y_pred=pred_lab,y_true=true_lab)\n",
    "                profile_arr.append(profile)\n",
    "                idp_arr.append(idp)\n",
    "                accu_arr.append(accu)\n",
    "            log = pd.DataFrame.from_dict({'profile':profile_arr,'IDP':idp_arr,'accu':accu_arr})\n",
    "            log.to_csv(config['result_file'],index=None)\n",
    "            print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profile = \"harmonic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_dir = \"~/IDP/output/1_\"\n",
    "epochs = 100\n",
    "batch_per_epoch = 200\n",
    "batch_size = 28\n",
    "learning_rate = 0.001\n",
    "config = {'epochs': epochs,\n",
    "          'batch_per_epoch': batch_per_epoch,\n",
    "          'batch_size': batch_size,\n",
    "          'learning_rate': learning_rate,\n",
    "          'save_dir': save_dir,\n",
    "          'log_file': save_dir+profile+\"_log.csv\",\n",
    "          'result_file': save_dir+profile+\"_result.csv\",\n",
    "          'mnist': mnist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    with tf.variable_scope(\"run2\") as scope:\n",
    "        model_test = model(profile)\n",
    "        log = model_test.train(sess=sess,config=config,gamma_trainable=False,reuse=False,verbose=False)\n",
    "        log = pd.DataFrame.from_dict(log)\n",
    "        #log.to_csv(config['log_file'],index=None)\n",
    "        #print(log)\n",
    "\n",
    "        true_lab = [np.argmax(ite) for ite in mnist.test.labels]\n",
    "        profile_arr = []\n",
    "        idp_arr = []\n",
    "        accu_arr = []\n",
    "        for idp in np.arange(0.1,1.05,0.05):  \n",
    "            probs = model_test.predict(sess=sess,config=config,idp=idp,scope='i'+str(int(idp*100)))\n",
    "            pred_lab = [np.argmax(ite) for ite in probs[0]]\n",
    "            accu = accuracy_score(y_pred=pred_lab,y_true=true_lab)\n",
    "            profile_arr.append(profile)\n",
    "            idp_arr.append(idp)\n",
    "            accu_arr.append(accu)\n",
    "        log = pd.DataFrame.from_dict({'profile':profile_arr,'IDP':idp_arr,'accu':accu_arr})\n",
    "        #log.to_csv(config['result_file'],index=None)\n",
    "        print(log)\n",
    "        \n",
    "        print(\"============ FURTHER TRAINING ============\")\n",
    "        scope.reuse_variables()\n",
    "        \n",
    "        config['epochs'] = 50\n",
    "        config['learning']\n",
    "        log = model_test.train(sess=sess,config=config,gamma_trainable=True,reuse=True,verbose=False)\n",
    "        log = pd.DataFrame.from_dict(log)\n",
    "        #log.to_csv(config['log_file'],index=None)\n",
    "        #print(log)\n",
    "\n",
    "        true_lab = [np.argmax(ite) for ite in mnist.test.labels]\n",
    "        profile_arr = []\n",
    "        idp_arr = []\n",
    "        accu_arr = []\n",
    "        for idp in np.arange(0.1,1.05,0.05):  \n",
    "            probs = model_test.predict(sess=sess,config=config,idp=idp,scope='i'+str(int(idp*100)))\n",
    "            pred_lab = [np.argmax(ite) for ite in probs[0]]\n",
    "            accu = accuracy_score(y_pred=pred_lab,y_true=true_lab)\n",
    "            profile_arr.append(profile)\n",
    "            idp_arr.append(idp)\n",
    "            accu_arr.append(accu)\n",
    "        log = pd.DataFrame.from_dict({'profile':profile_arr,'IDP':idp_arr,'accu':accu_arr})\n",
    "        #log.to_csv(config['result_file'],index=None)\n",
    "        print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
