{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class model():\n",
    "    def __init__(self,profile):\n",
    "        self.x = tf.placeholder(tf.float32, [None, 784])\n",
    "        self.y = tf.placeholder(tf.int32,[None,10])\n",
    "        self.learning_rate = 0.002\n",
    "        self.profile = profile\n",
    "\n",
    "        self.W1 = tf.get_variable(initializer=tf.random_uniform([784, 100],-0.1,0.1),name=\"W1\")\n",
    "        self.b1 = tf.get_variable(initializer=tf.random_uniform([100],-0.1,0.1),name=\"b1\")\n",
    "        self.W2 = tf.get_variable(initializer=tf.random_uniform([100, 100],-0.1,0.1),name=\"W2\")\n",
    "        self.b2 = tf.get_variable(initializer=tf.random_uniform([100],-0.1,0.1),name=\"b2\")\n",
    "        self.W3 = tf.get_variable(initializer=tf.random_uniform([100, 10],-0.1,0.1),name=\"W3\")\n",
    "        self.b3 = tf.get_variable(initializer=tf.random_uniform([10],-0.1,0.1),name=\"b3\")\n",
    "        \n",
    "        def half_exp(n,k=1,dtype='float32'):\n",
    "            n_ones = int(n/2)\n",
    "            n_other = n - int(n/2)\n",
    "            return np.append(np.ones(n_ones,dtype=dtype),np.exp((1-k)*np.arange(n_other),dtype=dtype))\n",
    "\n",
    "        if profile == \"linear\":\n",
    "            self.r1 = tf.get_variable(initializer=np.linspace(1,0,num=100,endpoint=False,dtype='float32'),name=\"r1\",dtype='float32')\n",
    "            self.r2 = tf.get_variable(initializer=np.linspace(1,0,num=100,endpoint=False,dtype='float32'),name=\"r2\",dtype='float32')\n",
    "            self.r3 = tf.get_variable(initializer=np.linspace(1,0,num=10,endpoint=False,dtype='float32') ,name=\"r3\",dtype='float32')\n",
    "        elif profile == \"all-one\":\n",
    "            self.r1 = tf.get_variable(initializer=np.ones(100,dtype='float32'),name=\"r1\",dtype='float32')\n",
    "            self.r2 = tf.get_variable(initializer=np.ones(100,dtype='float32'),name=\"r2\",dtype='float32')\n",
    "            self.r3 = tf.get_variable(initializer=np.ones(10 ,dtype='float32'),name=\"r3\",dtype='float32')\n",
    "        elif profile == \"half-exp\":\n",
    "            self.r1 = tf.get_variable(initializer=half_exp(100,1),name=\"r1\",dtype='float32')\n",
    "            self.r2 = tf.get_variable(initializer=half_exp(100,1),name=\"r2\",dtype='float32')\n",
    "            self.r3 = tf.get_variable(initializer=half_exp(10 ,1),name=\"r3\",dtype='float32')\n",
    "        else:\n",
    "            self.r1 = tf.get_variable(initializer=np.array(1.0/(np.arange(100)+1),dtype='float32'),name=\"r1\",dtype='float32')\n",
    "            self.r2 = tf.get_variable(initializer=np.array(1.0/(np.arange(100)+1),dtype='float32'),name=\"r2\",dtype='float32')\n",
    "            self.r3 = tf.get_variable(initializer=np.array(1.0/(np.arange(10)+1),dtype='float32') ,name=\"r3\",dtype='float32')\n",
    "\n",
    "    def train(self,sess,config,gamma_trainable=False,verbose=True):\n",
    "        # calculate r1*(W1*x)+b\n",
    "        z1 = tf.add(tf.multiply(self.r1,tf.matmul(self.x,self.W1)),self.b1)\n",
    "        y1 = tf.nn.relu(z1)\n",
    "        z2 = tf.add(tf.multiply(self.r2,tf.matmul(y1,self.W2)),self.b2)\n",
    "        y2 = tf.nn.relu(z2)\n",
    "\n",
    "        self.logits = tf.add(tf.multiply(self.r3,tf.matmul(y2,self.W3)),self.b3)\n",
    "        self.probs = tf.nn.softmax(self.logits)\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=self.logits,labels=self.y)\n",
    "        self.loss = tf.reduce_mean(cross_entropy)\n",
    "        \n",
    "        correct_prediction = tf.equal(tf.argmax(self.probs,1), tf.argmax(self.y,1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        tvars_trainable = tf.trainable_variables()\n",
    "        gamma_vars = [self.r1,self.r2,self.r3]\n",
    "        if gamma_trainable:\n",
    "            print('Only gamma(s) are trainable.')\n",
    "            self.tvars_trainable = gamma_vars\n",
    "        else:\n",
    "            for rm in gamma_vars:\n",
    "                tvars_trainable.remove(rm)\n",
    "                print('%s is not trainable.'% rm)\n",
    "            self.tvars_trainable = tvars_trainable\n",
    "\n",
    "        tvars = tf.trainable_variables()\n",
    "        self.tvars = tvars\n",
    "        self.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss,var_list=self.tvars_trainable)\n",
    "        \n",
    "        for v in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES):\n",
    "            sess.run(v.initializer)\n",
    "        print(\"Initialized.\")\n",
    "\n",
    "#         if init:\n",
    "#         uninitialized_vars = [tf.is_variable_initialized(v) for v in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)]\n",
    "#         for v in uninitialized_vars:\n",
    "#             sess.run(v.initializer)\n",
    "#         print(\"Initialized.\")\n",
    "\n",
    "        epochs = config['epochs']\n",
    "        batch_per_epoch = config['batch_per_epoch']\n",
    "        batch_size = config['batch_size']\n",
    "        save_dir = config['save_dir']\n",
    "        mnist = config['mnist']\n",
    "\n",
    "        #saver = tf.train.Saver(tf.global_variables())\n",
    "        val_loss_per_epoch = []\n",
    "        val_accu_per_epoch = []\n",
    "        loss_per_epoch = []\n",
    "        accu_per_epoch = []\n",
    "        for epoch in range(0,epochs):\n",
    "            start_time = time.time()\n",
    "            train_loss = []\n",
    "            train_accu = []\n",
    "            for batch in range(0,batch_per_epoch):\n",
    "                batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                _,loss, accu = sess.run([self.train_op, self.loss, self.accuracy], \n",
    "                                  feed_dict = {self.x:batch_x, self.y: batch_y})\n",
    "                train_loss.append(loss)\n",
    "                train_accu.append(accu)\n",
    "            loss_per_epoch.append(np.mean(train_loss))\n",
    "            accu_per_epoch.append(np.mean(train_accu))\n",
    "            \n",
    "            # test after one epoch\n",
    "            val_loss , probs, val_accu = sess.run([self.loss,self.probs,self.accuracy],feed_dict={self.x:mnist.test.images, self.y:mnist.test.labels})\n",
    "            val_loss_per_epoch.append(val_loss)\n",
    "            val_accu_per_epoch.append(val_accu)\n",
    "            if verbose:\n",
    "                print(\" epoch: %3d \\t time: %3f \\t loss: %3f \\t val_loss: %3f \\t accu: %3f \\t val_accu: %3f\"% \n",
    "                  (epoch,time.time() - start_time,np.mean(train_loss), val_loss, np.mean(train_accu), val_accu))\n",
    "        return({'loss':loss_per_epoch, 'val_loss':val_loss_per_epoch,'accu':accu_per_epoch,'val_accu':val_accu_per_epoch})\n",
    "    \n",
    "    def predict(self,sess,config,idp,scope):\n",
    "        with tf.variable_scope(scope):\n",
    "            # use variable t to control the on/off of neurons\n",
    "            n_ones = int(100 * idp)\n",
    "            n_zeros = 100 - n_ones\n",
    "            t1 = tf.get_variable(initializer=np.append(np.ones(n_ones,dtype='float32'),np.zeros(n_zeros,dtype='float32')),name=\"t1\",dtype='float32')\n",
    "\n",
    "            n_ones = int(100 * idp)\n",
    "            n_zeros = 100 - n_ones\n",
    "            t2 = tf.get_variable(initializer=np.append(np.ones(n_ones,dtype='float32'),np.zeros(n_zeros,dtype='float32')),name=\"t2\",dtype='float32')\n",
    "\n",
    "            n_ones = int(10 * idp)\n",
    "            n_zeros = 10 - n_ones\n",
    "            t3 = tf.get_variable(initializer=np.append(np.ones(n_ones,dtype='float32'),np.zeros(n_zeros,dtype='float32')),name=\"t3\",dtype='float32')\n",
    "\n",
    "            p1 = tf.get_variable(initializer=tf.multiply(self.r1,t1),name=\"p1\")\n",
    "            p2 = tf.get_variable(initializer=tf.multiply(self.r2,t2),name=\"p2\")\n",
    "            p3 = tf.get_variable(initializer=tf.multiply(self.r3,t3),name=\"p3\")\n",
    "\n",
    "            for v in [t1,t2,t3,p1,p2,p3]:\n",
    "                sess.run(v.initializer)\n",
    "            print(\"Initialized IDP mechanism {:.0f}%\".format(idp*100))\n",
    "            \n",
    "            #sess.run(tf.pack([tf.is_variable_initialized(v) for v in [t1,t2,t3,p1,p2,p3]]))\n",
    "            #print(\"Initialized IDP mechanism.\")\n",
    "\n",
    "            z1 = tf.add(tf.multiply(p1,tf.matmul(self.x,self.W1)),self.b1)\n",
    "            y1 = tf.nn.relu(z1)\n",
    "            # IDP on layer 2\n",
    "            z2 = tf.add(tf.multiply(p2,tf.matmul(y1,self.W2)),self.b2)\n",
    "            y2 = tf.nn.relu(z2)\n",
    "            logits = tf.add(tf.multiply(self.r3,tf.matmul(y2,self.W3)),self.b3)\n",
    "            self.pred_probs = tf.nn.softmax(logits)\n",
    "\n",
    "            mnist = config['mnist']\n",
    "            pred_probs = sess.run([self.pred_probs],\n",
    "                                        feed_dict={self.x:mnist.test.images, self.y:mnist.test.labels})\n",
    "            return(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "profile_test = [\"all-one\",\"linear\",\"harmonic\",\"half-exp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-one\n",
      "<tf.Variable 'all-one1/r1:0' shape=(100,) dtype=float32_ref> is not trainable.\n",
      "<tf.Variable 'all-one1/r2:0' shape=(100,) dtype=float32_ref> is not trainable.\n",
      "<tf.Variable 'all-one1/r3:0' shape=(10,) dtype=float32_ref> is not trainable.\n",
      "Initialized.\n",
      "        accu      loss  val_accu  val_loss\n",
      "0   0.841667  0.545842    0.9130  0.302477\n",
      "1   0.925750  0.252165    0.9343  0.214563\n",
      "2   0.937833  0.208315    0.9447  0.177716\n",
      "3   0.946333  0.176623    0.9561  0.147335\n",
      "4   0.956333  0.143239    0.9568  0.138218\n",
      "5   0.960750  0.127933    0.9645  0.112168\n",
      "6   0.965083  0.110532    0.9586  0.134073\n",
      "7   0.966750  0.111450    0.9675  0.107537\n",
      "8   0.966250  0.107685    0.9666  0.111564\n",
      "9   0.974167  0.085308    0.9670  0.104845\n",
      "10  0.977083  0.076766    0.9695  0.104262\n",
      "11  0.973833  0.081369    0.9709  0.095342\n",
      "12  0.974333  0.080327    0.9694  0.099576\n",
      "13  0.974917  0.079940    0.9740  0.083787\n",
      "14  0.980417  0.059588    0.9719  0.091361\n",
      "15  0.980417  0.059187    0.9675  0.106525\n",
      "16  0.979750  0.061087    0.9733  0.090419\n",
      "17  0.980333  0.062036    0.9754  0.086652\n",
      "18  0.986167  0.046509    0.9720  0.096308\n",
      "19  0.986417  0.043627    0.9718  0.097340\n",
      "20  0.982750  0.052246    0.9777  0.076859\n",
      "21  0.980667  0.055912    0.9741  0.088592\n",
      "22  0.981917  0.055685    0.9729  0.091785\n",
      "23  0.990583  0.032724    0.9769  0.082977\n",
      "24  0.987833  0.038583    0.9722  0.095672\n",
      "25  0.986000  0.039825    0.9743  0.091744\n",
      "26  0.983083  0.048268    0.9712  0.102290\n",
      "27  0.987833  0.036103    0.9758  0.086417\n",
      "28  0.990833  0.028988    0.9780  0.081053\n",
      "29  0.987250  0.038060    0.9753  0.093332\n",
      "30  0.986667  0.039587    0.9781  0.077648\n",
      "31  0.988583  0.033322    0.9738  0.095663\n",
      "32  0.991083  0.028209    0.9756  0.090286\n",
      "33  0.990583  0.028252    0.9748  0.097276\n",
      "34  0.989583  0.029706    0.9779  0.085431\n",
      "35  0.988250  0.035626    0.9706  0.116000\n",
      "36  0.985667  0.044706    0.9798  0.082167\n",
      "37  0.992333  0.021883    0.9800  0.076776\n",
      "38  0.992750  0.021528    0.9783  0.078566\n",
      "39  0.992167  0.022692    0.9748  0.107773\n",
      "40  0.987917  0.035339    0.9728  0.105864\n",
      "41  0.990500  0.026840    0.9769  0.096642\n",
      "42  0.994250  0.018606    0.9776  0.096234\n",
      "43  0.992417  0.023597    0.9789  0.090017\n",
      "44  0.991833  0.023903    0.9789  0.085906\n",
      "45  0.991083  0.028715    0.9744  0.109080\n",
      "46  0.992250  0.022615    0.9779  0.099542\n",
      "47  0.993583  0.021046    0.9783  0.095964\n",
      "48  0.992250  0.023005    0.9759  0.114273\n",
      "49  0.992250  0.023653    0.9792  0.093140\n",
      "Initialized IDP mechanism 10%\n",
      "Initialized IDP mechanism 20%\n",
      "Initialized IDP mechanism 30%\n",
      "Initialized IDP mechanism 40%\n",
      "Initialized IDP mechanism 50%\n",
      "Initialized IDP mechanism 60%\n",
      "Initialized IDP mechanism 70%\n",
      "Initialized IDP mechanism 80%\n",
      "Initialized IDP mechanism 90%\n",
      "Initialized IDP mechanism 100%\n",
      "   IDP    accu  profile\n",
      "0  0.1  0.1172  all-one\n",
      "1  0.2  0.3013  all-one\n",
      "2  0.3  0.5189  all-one\n",
      "3  0.4  0.6184  all-one\n",
      "4  0.5  0.7601  all-one\n",
      "5  0.6  0.8384  all-one\n",
      "6  0.7  0.8882  all-one\n",
      "7  0.8  0.9532  all-one\n",
      "8  0.9  0.9695  all-one\n",
      "9  1.0  0.9792  all-one\n",
      "linear\n",
      "<tf.Variable 'linear1/r1:0' shape=(100,) dtype=float32_ref> is not trainable.\n",
      "<tf.Variable 'linear1/r2:0' shape=(100,) dtype=float32_ref> is not trainable.\n",
      "<tf.Variable 'linear1/r3:0' shape=(10,) dtype=float32_ref> is not trainable.\n"
     ]
    }
   ],
   "source": [
    "counter = counter + 1\n",
    "for profile in profile_test:\n",
    "    print(profile)\n",
    "    with tf.variable_scope(profile+str(counter)):\n",
    "        model_test = model(profile=profile)\n",
    "        save_dir = \"~/IDP/output/1_\"\n",
    "        epochs = 50\n",
    "        batch_per_epoch = 200\n",
    "        batch_size = 60\n",
    "        learning_rate = 0.005\n",
    "        config = {'epochs': epochs,\n",
    "                  'batch_per_epoch': batch_per_epoch,\n",
    "                  'batch_size': batch_size,\n",
    "                  'learning_rate': learning_rate,\n",
    "                  'save_dir': save_dir,\n",
    "                  'log_file': save_dir+profile+\"_log.csv\",\n",
    "                  'result_file': save_dir+profile+\"_result.csv\",\n",
    "                  'mnist': mnist}\n",
    "        with tf.Session() as sess:\n",
    "            log = model_test.train(sess=sess,config=config,gamma_trainable=False,verbose=False)\n",
    "            log = pd.DataFrame.from_dict(log)\n",
    "            log.to_csv(config['log_file'],index=None)\n",
    "            print(log)\n",
    "            \n",
    "            true_lab = [np.argmax(ite) for ite in mnist.test.labels]\n",
    "            profile_arr = []\n",
    "            idp_arr = []\n",
    "            accu_arr = []\n",
    "            for idp in np.arange(0.1,1.1,0.1):  \n",
    "                probs = model_test.predict(sess=sess,config=config,idp=idp,scope='i'+str(int(idp*100)))\n",
    "                pred_lab = [np.argmax(ite) for ite in probs[0]]\n",
    "                accu = accuracy_score(y_pred=pred_lab,y_true=true_lab)\n",
    "                profile_arr.append(profile)\n",
    "                idp_arr.append(idp)\n",
    "                accu_arr.append(accu)\n",
    "            log = pd.DataFrame.from_dict({'profile':profile_arr,'IDP':idp_arr,'accu':accu_arr})\n",
    "            log.to_csv(config['result_file'],index=None)\n",
    "            print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
