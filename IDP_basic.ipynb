{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model():\n",
    "    def __init__(self,profile):\n",
    "        self.x = tf.placeholder(tf.float32, [None, 784])\n",
    "        self.y = tf.placeholder(tf.int32,[None,10])\n",
    "        self.profile = profile\n",
    "\n",
    "        self.W1 = tf.get_variable(initializer=tf.random_uniform([784, 100],-0.1,0.1),name=\"W1\")\n",
    "        self.b1 = tf.get_variable(initializer=tf.random_uniform([100],-0.1,0.1),name=\"b1\")\n",
    "        self.W2 = tf.get_variable(initializer=tf.random_uniform([100, 100],-0.1,0.1),name=\"W2\")\n",
    "        self.b2 = tf.get_variable(initializer=tf.random_uniform([100],-0.1,0.1),name=\"b2\")\n",
    "        self.W3 = tf.get_variable(initializer=tf.random_uniform([100, 10],-0.1,0.1),name=\"W3\")\n",
    "        self.b3 = tf.get_variable(initializer=tf.random_uniform([10],-0.1,0.1),name=\"b3\")\n",
    "        \n",
    "        def half_exp(n,k=1,dtype='float32'):\n",
    "            n_ones = int(n/2)\n",
    "            n_other = n - int(n/2)\n",
    "            return np.append(np.ones(n_ones,dtype=dtype),np.exp((1-k)*np.arange(n_other),dtype=dtype))\n",
    "\n",
    "        if profile == \"linear\":\n",
    "            self.r1 = tf.get_variable(initializer=np.linspace(1,0,num=784,endpoint=False,dtype='float32'),name=\"r1\",dtype='float32')\n",
    "            self.r2 = tf.get_variable(initializer=np.linspace(1,0,num=100,endpoint=False,dtype='float32'),name=\"r2\",dtype='float32')\n",
    "            self.r3 = tf.get_variable(initializer=np.linspace(1,0,num=100,endpoint=False,dtype='float32') ,name=\"r3\",dtype='float32')\n",
    "        elif profile == \"all-one\":\n",
    "            self.r1 = tf.get_variable(initializer=np.ones(784,dtype='float32'),name=\"r1\",dtype='float32')\n",
    "            self.r2 = tf.get_variable(initializer=np.ones(100,dtype='float32'),name=\"r2\",dtype='float32')\n",
    "            self.r3 = tf.get_variable(initializer=np.ones(100,dtype='float32'),name=\"r3\",dtype='float32')\n",
    "        elif profile == \"half-exp\":\n",
    "            self.r1 = tf.get_variable(initializer=half_exp(784,2),name=\"r1\",dtype='float32')\n",
    "            self.r2 = tf.get_variable(initializer=half_exp(100,2),name=\"r2\",dtype='float32')\n",
    "            self.r3 = tf.get_variable(initializer=half_exp(100,2),name=\"r3\",dtype='float32')\n",
    "        else:\n",
    "            self.r1 = tf.get_variable(initializer=np.array(1.0/(np.arange(784)+1),dtype='float32'),name=\"r1\",dtype='float32')\n",
    "            self.r2 = tf.get_variable(initializer=np.array(1.0/(np.arange(100)+1),dtype='float32'),name=\"r2\",dtype='float32')\n",
    "            self.r3 = tf.get_variable(initializer=np.array(1.0/(np.arange(100)+1),dtype='float32') ,name=\"r3\",dtype='float32')\n",
    "\n",
    "    def train(self,sess,config,gamma_trainable=False,verbose=True):\n",
    "        self.learning_rate = config[\"learning_rate\"]\n",
    "        # calculate r1*(W1*x)+b\n",
    "        #z1 = tf.add(tf.multiply(self.r1,tf.matmul(self.x,self.W1)),self.b1)\n",
    "        #z1 = tf.add(tf.matmul(tf.multiply(self.r1,self.x),self.W1),self.b1)\n",
    "        z1 = tf.add(tf.matmul(self.x,self.W1),self.b1)\n",
    "        y1 = tf.nn.relu(z1)\n",
    "        z2 = tf.add(tf.matmul(tf.multiply(self.r2,y1),self.W2),self.b2)\n",
    "        #z2 = tf.add(tf.multiply(self.r2,tf.matmul(y1,self.W2)),self.b2)\n",
    "        y2 = tf.nn.relu(z2)\n",
    "\n",
    "        #self.logits = tf.add(tf.multiply(self.r3,tf.matmul(y2,self.W3)),self.b3)\n",
    "        #self.logits = tf.add(tf.matmul(tf.multiply(self.r3,y2),self.W3),self.b3)\n",
    "        self.logits = tf.add(tf.matmul(y2,self.W3),self.b3)\n",
    "        self.probs = tf.nn.softmax(self.logits)\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=self.logits,labels=self.y)\n",
    "        self.loss = tf.reduce_mean(cross_entropy)\n",
    "        \n",
    "        correct_prediction = tf.equal(tf.argmax(self.probs,1), tf.argmax(self.y,1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        tvars_trainable = tf.trainable_variables()\n",
    "        gamma_vars = [self.r1,self.r2,self.r3]\n",
    "        if gamma_trainable:\n",
    "            print('Only gamma(s) are trainable.')\n",
    "            self.tvars_trainable = gamma_vars\n",
    "        else:\n",
    "            for rm in gamma_vars:\n",
    "                tvars_trainable.remove(rm)\n",
    "                print('%s is not trainable.'% rm)\n",
    "            self.tvars_trainable = tvars_trainable\n",
    "\n",
    "        tvars = tf.trainable_variables()\n",
    "        self.tvars = tvars\n",
    "        self.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss,var_list=self.tvars_trainable)\n",
    "        \n",
    "        for v in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES):\n",
    "            sess.run(v.initializer)\n",
    "        print(\"Initialized.\")\n",
    "\n",
    "#         if init:\n",
    "#         uninitialized_vars = [tf.is_variable_initialized(v) for v in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)]\n",
    "#         for v in uninitialized_vars:\n",
    "#             sess.run(v.initializer)\n",
    "#         print(\"Initialized.\")\n",
    "\n",
    "        epochs = config['epochs']\n",
    "        batch_per_epoch = config['batch_per_epoch']\n",
    "        batch_size = config['batch_size']\n",
    "        save_dir = config['save_dir']\n",
    "        mnist = config['mnist']\n",
    "\n",
    "        #saver = tf.train.Saver(tf.global_variables())\n",
    "        val_loss_per_epoch = []\n",
    "        val_accu_per_epoch = []\n",
    "        loss_per_epoch = []\n",
    "        accu_per_epoch = []\n",
    "        for epoch in range(0,epochs):\n",
    "            start_time = time.time()\n",
    "            train_loss = []\n",
    "            train_accu = []\n",
    "            for batch in range(0,batch_per_epoch):\n",
    "                batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                _,loss, accu = sess.run([self.train_op, self.loss, self.accuracy], \n",
    "                                  feed_dict = {self.x:batch_x, self.y: batch_y})\n",
    "                train_loss.append(loss)\n",
    "                train_accu.append(accu)\n",
    "            loss_per_epoch.append(np.mean(train_loss))\n",
    "            accu_per_epoch.append(np.mean(train_accu))\n",
    "            \n",
    "            # test after one epoch\n",
    "            val_loss , probs, val_accu = sess.run([self.loss,self.probs,self.accuracy],feed_dict={self.x:mnist.test.images, self.y:mnist.test.labels})\n",
    "            val_loss_per_epoch.append(val_loss)\n",
    "            val_accu_per_epoch.append(val_accu)\n",
    "            if verbose:\n",
    "                print(\" epoch: %3d \\t time: %3f \\t loss: %3f \\t val_loss: %3f \\t accu: %3f \\t val_accu: %3f\"% \n",
    "                  (epoch,time.time() - start_time,np.mean(train_loss), val_loss, np.mean(train_accu), val_accu))\n",
    "        return({'loss':loss_per_epoch, 'val_loss':val_loss_per_epoch,'accu':accu_per_epoch,'val_accu':val_accu_per_epoch})\n",
    "    \n",
    "    def predict(self,sess,config,idp,scope):\n",
    "        with tf.variable_scope(scope):\n",
    "            # use variable t to control the on/off of neurons\n",
    "            n_ones = int(784 * idp)\n",
    "            n_zeros = 784 - n_ones\n",
    "            t1 = tf.get_variable(initializer=np.append(np.ones(n_ones,dtype='float32'),np.zeros(n_zeros,dtype='float32')),name=\"t1\",dtype='float32')\n",
    "\n",
    "            n_ones = int(100 * idp)\n",
    "            n_zeros = 100 - n_ones\n",
    "            t2 = tf.get_variable(initializer=np.append(np.ones(n_ones,dtype='float32'),np.zeros(n_zeros,dtype='float32')),name=\"t2\",dtype='float32')\n",
    "\n",
    "            n_ones = int(100 * idp)\n",
    "            n_zeros = 100 - n_ones\n",
    "            t3 = tf.get_variable(initializer=np.append(np.ones(n_ones,dtype='float32'),np.zeros(n_zeros,dtype='float32')),name=\"t3\",dtype='float32')\n",
    "\n",
    "            p1 = tf.get_variable(initializer=tf.multiply(self.r1,t1),name=\"p1\")\n",
    "            p2 = tf.get_variable(initializer=tf.multiply(self.r2,t2),name=\"p2\")\n",
    "            p3 = tf.get_variable(initializer=tf.multiply(self.r3,t3),name=\"p3\")\n",
    "\n",
    "            for v in [t1,t2,t3,p1,p2,p3]:\n",
    "                sess.run(v.initializer)\n",
    "                #print(sess.run(v))\n",
    "            print(\"Initialized IDP mechanism {:.0f}%\".format(idp*100))\n",
    "            \n",
    "            #sess.run(tf.pack([tf.is_variable_initialized(v) for v in [t1,t2,t3,p1,p2,p3]]))\n",
    "            #print(\"Initialized IDP mechanism.\")\n",
    "\n",
    "            #z1 = tf.add(tf.multiply(self.r1,tf.matmul(self.x,self.W1)),self.b1)\n",
    "            #z1 = tf.add(tf.matmul(tf.multiply(self.r1,self.x),self.W1),self.b1)\n",
    "            z1 = tf.add(tf.matmul(self.x,self.W1),self.b1)\n",
    "            y1 = tf.nn.relu(z1)\n",
    "            # IDP on layer 2\n",
    "            #z2 = tf.add(tf.multiply(p2,tf.matmul(y1,self.W2)),self.b2)\n",
    "            z2 = tf.add(tf.matmul(tf.multiply(p2,y1),self.W2),self.b2)\n",
    "            y2 = tf.nn.relu(z2)\n",
    "            #logits = tf.add(tf.multiply(self.r3,tf.matmul(y2,self.W3)),self.b3)\n",
    "            #logits = tf.add(tf.matmul(tf.multiply(self.r3,y2),self.W3),self.b3)\n",
    "            logits = tf.add(tf.matmul(y2,self.W3),self.b3)\n",
    "            self.pred_probs = tf.nn.softmax(logits)\n",
    "\n",
    "            mnist = config['mnist']\n",
    "            pred_probs = sess.run([self.pred_probs],\n",
    "                                        feed_dict={self.x:mnist.test.images, self.y:mnist.test.labels})\n",
    "            return(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profile_test = [\"all-one\",\"linear\",\"harmonic\",\"half-exp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-one\n",
      "<tf.Variable 'all-one3/r1:0' shape=(784,) dtype=float32_ref> is not trainable.\n",
      "<tf.Variable 'all-one3/r2:0' shape=(100,) dtype=float32_ref> is not trainable.\n",
      "<tf.Variable 'all-one3/r3:0' shape=(100,) dtype=float32_ref> is not trainable.\n",
      "Initialized.\n",
      "        accu      loss  val_accu  val_loss\n",
      "0   0.757857  0.836812    0.8781  0.384214\n",
      "1   0.901607  0.353790    0.9140  0.286173\n",
      "2   0.916786  0.288675    0.9290  0.234221\n",
      "3   0.925000  0.248689    0.9372  0.210662\n",
      "4   0.937500  0.219041    0.9350  0.214593\n",
      "5   0.944464  0.184758    0.9420  0.192069\n",
      "6   0.945714  0.187230    0.9467  0.165428\n",
      "7   0.942143  0.189745    0.9499  0.155266\n",
      "8   0.948929  0.160623    0.9535  0.147085\n",
      "9   0.956786  0.142273    0.9568  0.142466\n",
      "10  0.957143  0.140780    0.9604  0.130423\n",
      "11  0.962143  0.131385    0.9545  0.145287\n",
      "12  0.962321  0.131593    0.9574  0.137477\n",
      "13  0.958393  0.126536    0.9604  0.128575\n",
      "14  0.954643  0.146404    0.9594  0.133653\n",
      "15  0.967857  0.105569    0.9619  0.122166\n",
      "16  0.969821  0.101895    0.9624  0.122566\n",
      "17  0.968571  0.104313    0.9624  0.124153\n",
      "18  0.967500  0.105109    0.9652  0.108298\n",
      "19  0.967679  0.105145    0.9627  0.118146\n",
      "20  0.970893  0.085608    0.9661  0.109973\n",
      "21  0.971786  0.092318    0.9623  0.116187\n",
      "22  0.968393  0.104192    0.9655  0.110905\n",
      "23  0.971786  0.092631    0.9684  0.101234\n",
      "24  0.969286  0.101055    0.9693  0.096737\n",
      "25  0.976964  0.074181    0.9701  0.094826\n",
      "26  0.974643  0.078068    0.9701  0.100459\n",
      "27  0.977500  0.075608    0.9713  0.091750\n",
      "28  0.978036  0.068753    0.9675  0.104698\n",
      "29  0.975893  0.075396    0.9674  0.105400\n",
      "..       ...       ...       ...       ...\n",
      "50  0.984821  0.049502    0.9715  0.097663\n",
      "51  0.985357  0.042116    0.9765  0.082264\n",
      "52  0.983571  0.051296    0.9745  0.085876\n",
      "53  0.985179  0.046980    0.9769  0.081483\n",
      "54  0.985714  0.042127    0.9753  0.090254\n",
      "55  0.986786  0.038213    0.9740  0.087245\n",
      "56  0.989643  0.032003    0.9751  0.088751\n",
      "57  0.990714  0.031719    0.9736  0.099061\n",
      "58  0.985714  0.037087    0.9778  0.082756\n",
      "59  0.986429  0.039440    0.9741  0.086545\n",
      "60  0.987321  0.035762    0.9751  0.093144\n",
      "61  0.988929  0.039972    0.9715  0.101148\n",
      "62  0.988750  0.033637    0.9750  0.087397\n",
      "63  0.987857  0.040039    0.9777  0.082761\n",
      "64  0.990000  0.034674    0.9749  0.091658\n",
      "65  0.990714  0.027216    0.9766  0.084958\n",
      "66  0.990893  0.026214    0.9754  0.090580\n",
      "67  0.990714  0.023791    0.9760  0.084535\n",
      "68  0.990357  0.026531    0.9769  0.084514\n",
      "69  0.989286  0.031313    0.9759  0.092217\n",
      "70  0.989821  0.031239    0.9746  0.097665\n",
      "71  0.988571  0.036492    0.9751  0.098044\n",
      "72  0.990179  0.031088    0.9754  0.098667\n",
      "73  0.990714  0.032516    0.9769  0.088671\n",
      "74  0.989286  0.032196    0.9755  0.093599\n",
      "75  0.989286  0.034272    0.9797  0.083011\n",
      "76  0.992679  0.019580    0.9786  0.085194\n",
      "77  0.993214  0.021930    0.9802  0.080565\n",
      "78  0.990714  0.026129    0.9773  0.090127\n",
      "79  0.990179  0.026868    0.9762  0.100410\n",
      "\n",
      "[80 rows x 4 columns]\n",
      "Initialized IDP mechanism 10%\n",
      "Initialized IDP mechanism 15%\n",
      "Initialized IDP mechanism 20%\n",
      "Initialized IDP mechanism 25%\n",
      "Initialized IDP mechanism 30%\n",
      "Initialized IDP mechanism 35%\n",
      "Initialized IDP mechanism 40%\n",
      "Initialized IDP mechanism 45%\n",
      "Initialized IDP mechanism 50%\n",
      "Initialized IDP mechanism 55%\n",
      "Initialized IDP mechanism 60%\n",
      "Initialized IDP mechanism 65%\n",
      "Initialized IDP mechanism 70%\n",
      "Initialized IDP mechanism 75%\n",
      "Initialized IDP mechanism 80%\n",
      "Initialized IDP mechanism 85%\n",
      "Initialized IDP mechanism 90%\n",
      "Initialized IDP mechanism 95%\n",
      "Initialized IDP mechanism 100%\n",
      "     IDP    accu  profile\n",
      "0   0.10  0.4046  all-one\n",
      "1   0.15  0.5024  all-one\n",
      "2   0.20  0.5210  all-one\n",
      "3   0.25  0.6518  all-one\n",
      "4   0.30  0.6866  all-one\n",
      "5   0.35  0.7061  all-one\n",
      "6   0.40  0.7214  all-one\n",
      "7   0.45  0.7622  all-one\n",
      "8   0.50  0.8023  all-one\n",
      "9   0.55  0.8639  all-one\n",
      "10  0.60  0.8736  all-one\n",
      "11  0.65  0.8737  all-one\n",
      "12  0.70  0.8916  all-one\n",
      "13  0.75  0.8998  all-one\n",
      "14  0.80  0.9521  all-one\n",
      "15  0.85  0.9610  all-one\n",
      "16  0.90  0.9651  all-one\n",
      "17  0.95  0.9714  all-one\n",
      "18  1.00  0.9762  all-one\n",
      "linear\n",
      "<tf.Variable 'linear3/r1:0' shape=(784,) dtype=float32_ref> is not trainable.\n",
      "<tf.Variable 'linear3/r2:0' shape=(100,) dtype=float32_ref> is not trainable.\n",
      "<tf.Variable 'linear3/r3:0' shape=(100,) dtype=float32_ref> is not trainable.\n",
      "Initialized.\n",
      "        accu      loss  val_accu  val_loss\n",
      "0   0.731607  0.945943    0.8823  0.422533\n",
      "1   0.888572  0.380950    0.9032  0.327493\n",
      "2   0.905179  0.323361    0.9195  0.275507\n",
      "3   0.916607  0.286106    0.9181  0.273363\n",
      "4   0.925893  0.240359    0.9287  0.238942\n",
      "5   0.931607  0.244643    0.9388  0.210823\n",
      "6   0.937857  0.209405    0.9437  0.193669\n",
      "7   0.939464  0.200985    0.9457  0.181266\n",
      "8   0.944286  0.191445    0.9535  0.159193\n",
      "9   0.947143  0.183862    0.9553  0.155772\n",
      "10  0.951072  0.158070    0.9518  0.160953\n",
      "11  0.954464  0.154528    0.9513  0.154652\n",
      "12  0.950357  0.160684    0.9584  0.141440\n",
      "13  0.957679  0.139597    0.9624  0.129361\n",
      "14  0.965179  0.119639    0.9612  0.133202\n",
      "15  0.959286  0.134691    0.9596  0.128096\n",
      "16  0.965357  0.115996    0.9587  0.132066\n",
      "17  0.962500  0.126737    0.9617  0.122627\n",
      "18  0.963929  0.114015    0.9650  0.113039\n",
      "19  0.968214  0.111497    0.9665  0.109806\n",
      "20  0.965179  0.110003    0.9660  0.110599\n",
      "21  0.966250  0.105319    0.9655  0.113264\n",
      "22  0.964107  0.114659    0.9658  0.108351\n",
      "23  0.969821  0.100663    0.9691  0.100258\n",
      "24  0.976250  0.088031    0.9682  0.102956\n",
      "25  0.971429  0.083962    0.9725  0.092616\n",
      "26  0.973214  0.086439    0.9711  0.096796\n",
      "27  0.972857  0.091112    0.9677  0.105691\n",
      "28  0.979107  0.070081    0.9707  0.092816\n",
      "29  0.973929  0.086581    0.9673  0.103024\n",
      "..       ...       ...       ...       ...\n",
      "50  0.984107  0.052443    0.9772  0.077063\n",
      "51  0.980714  0.056239    0.9744  0.081520\n",
      "52  0.981786  0.056768    0.9738  0.084872\n",
      "53  0.983929  0.052844    0.9759  0.081618\n",
      "54  0.990357  0.032672    0.9749  0.079660\n",
      "55  0.987143  0.038559    0.9749  0.082224\n",
      "56  0.984643  0.048714    0.9733  0.087954\n",
      "57  0.986250  0.041287    0.9715  0.092037\n",
      "58  0.988571  0.038412    0.9771  0.075169\n",
      "59  0.988214  0.037599    0.9724  0.094324\n",
      "60  0.987679  0.036192    0.9738  0.092257\n",
      "61  0.983929  0.049546    0.9774  0.071221\n",
      "62  0.983393  0.052280    0.9751  0.082298\n",
      "63  0.991786  0.030384    0.9761  0.078111\n",
      "64  0.992679  0.024711    0.9773  0.080986\n",
      "65  0.988929  0.034113    0.9748  0.080934\n",
      "66  0.988393  0.038760    0.9758  0.077492\n",
      "67  0.988571  0.034587    0.9778  0.075120\n",
      "68  0.990179  0.032162    0.9749  0.087833\n",
      "69  0.987679  0.036041    0.9772  0.080696\n",
      "70  0.988393  0.034710    0.9771  0.079183\n",
      "71  0.986964  0.035117    0.9720  0.097860\n",
      "72  0.986071  0.042813    0.9749  0.080370\n",
      "73  0.992679  0.021920    0.9776  0.076993\n",
      "74  0.996071  0.014436    0.9794  0.077722\n",
      "75  0.990714  0.025162    0.9764  0.086884\n",
      "76  0.991429  0.026767    0.9778  0.081982\n",
      "77  0.988929  0.033027    0.9763  0.085616\n",
      "78  0.990357  0.031737    0.9791  0.078975\n",
      "79  0.991607  0.028708    0.9782  0.081251\n",
      "\n",
      "[80 rows x 4 columns]\n",
      "Initialized IDP mechanism 10%\n",
      "Initialized IDP mechanism 15%\n",
      "Initialized IDP mechanism 20%\n",
      "Initialized IDP mechanism 25%\n",
      "Initialized IDP mechanism 30%\n",
      "Initialized IDP mechanism 35%\n",
      "Initialized IDP mechanism 40%\n",
      "Initialized IDP mechanism 45%\n",
      "Initialized IDP mechanism 50%\n",
      "Initialized IDP mechanism 55%\n",
      "Initialized IDP mechanism 60%\n",
      "Initialized IDP mechanism 65%\n",
      "Initialized IDP mechanism 70%\n",
      "Initialized IDP mechanism 75%\n",
      "Initialized IDP mechanism 80%\n",
      "Initialized IDP mechanism 85%\n",
      "Initialized IDP mechanism 90%\n",
      "Initialized IDP mechanism 95%\n",
      "Initialized IDP mechanism 100%\n",
      "     IDP    accu profile\n",
      "0   0.10  0.3465  linear\n",
      "1   0.15  0.5194  linear\n",
      "2   0.20  0.6442  linear\n",
      "3   0.25  0.6842  linear\n",
      "4   0.30  0.7926  linear\n",
      "5   0.35  0.8320  linear\n",
      "6   0.40  0.8813  linear\n",
      "7   0.45  0.9084  linear\n",
      "8   0.50  0.9224  linear\n",
      "9   0.55  0.9419  linear\n",
      "10  0.60  0.9457  linear\n",
      "11  0.65  0.9572  linear\n",
      "12  0.70  0.9604  linear\n",
      "13  0.75  0.9698  linear\n",
      "14  0.80  0.9741  linear\n",
      "15  0.85  0.9732  linear\n",
      "16  0.90  0.9778  linear\n",
      "17  0.95  0.9785  linear\n",
      "18  1.00  0.9782  linear\n",
      "harmonic\n",
      "<tf.Variable 'harmonic3/r1:0' shape=(784,) dtype=float32_ref> is not trainable.\n",
      "<tf.Variable 'harmonic3/r2:0' shape=(100,) dtype=float32_ref> is not trainable.\n",
      "<tf.Variable 'harmonic3/r3:0' shape=(100,) dtype=float32_ref> is not trainable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized.\n",
      "        accu      loss  val_accu  val_loss\n",
      "0   0.538929  1.491884    0.7601  0.774463\n",
      "1   0.808929  0.635225    0.8490  0.514115\n",
      "2   0.856607  0.499243    0.8759  0.423319\n",
      "3   0.879286  0.408911    0.8925  0.379637\n",
      "4   0.888214  0.377394    0.8978  0.353077\n",
      "5   0.898393  0.342036    0.9039  0.328774\n",
      "6   0.901250  0.339526    0.9018  0.339185\n",
      "7   0.901786  0.333498    0.9124  0.302273\n",
      "8   0.911071  0.314510    0.9148  0.292973\n",
      "9   0.918036  0.296210    0.9181  0.277252\n",
      "10  0.915179  0.291590    0.9244  0.270323\n",
      "11  0.916964  0.294144    0.9236  0.266772\n",
      "12  0.920179  0.267648    0.9263  0.256453\n",
      "13  0.924286  0.263735    0.9284  0.247940\n",
      "14  0.925714  0.258090    0.9243  0.253026\n",
      "15  0.926786  0.249092    0.9305  0.241843\n",
      "16  0.931429  0.238158    0.9320  0.230147\n",
      "17  0.934107  0.237323    0.9298  0.232864\n",
      "18  0.932857  0.229905    0.9358  0.221830\n",
      "19  0.932857  0.228008    0.9326  0.227321\n",
      "20  0.931964  0.233753    0.9383  0.211269\n",
      "21  0.939464  0.209812    0.9402  0.205171\n",
      "22  0.944821  0.194213    0.9365  0.208311\n",
      "23  0.938572  0.203173    0.9437  0.194055\n",
      "24  0.948750  0.182424    0.9384  0.208781\n",
      "25  0.939821  0.212994    0.9430  0.188987\n",
      "26  0.948750  0.184937    0.9464  0.179485\n",
      "27  0.938214  0.200999    0.9444  0.190378\n",
      "28  0.951072  0.175934    0.9474  0.176434\n",
      "29  0.952322  0.171879    0.9469  0.179329\n",
      "..       ...       ...       ...       ...\n",
      "50  0.963929  0.117605    0.9598  0.132682\n",
      "51  0.964821  0.117514    0.9636  0.120391\n",
      "52  0.963571  0.119573    0.9619  0.126329\n",
      "53  0.968750  0.106250    0.9616  0.123854\n",
      "54  0.969286  0.102663    0.9617  0.124482\n",
      "55  0.966786  0.117626    0.9621  0.119816\n",
      "56  0.966429  0.111910    0.9644  0.113797\n",
      "57  0.968750  0.102379    0.9653  0.115185\n",
      "58  0.968929  0.101080    0.9643  0.119479\n",
      "59  0.968571  0.093479    0.9629  0.120448\n",
      "60  0.970000  0.101113    0.9667  0.112409\n",
      "61  0.969821  0.101625    0.9639  0.117049\n",
      "62  0.972857  0.088055    0.9651  0.112450\n",
      "63  0.968750  0.104223    0.9638  0.117692\n",
      "64  0.969821  0.102399    0.9626  0.123515\n",
      "65  0.971071  0.094455    0.9645  0.113178\n",
      "66  0.974107  0.085623    0.9640  0.111230\n",
      "67  0.972321  0.090828    0.9667  0.104434\n",
      "68  0.977321  0.077259    0.9647  0.111176\n",
      "69  0.972143  0.097530    0.9692  0.101124\n",
      "70  0.974286  0.082081    0.9680  0.101973\n",
      "71  0.975714  0.080729    0.9684  0.105180\n",
      "72  0.981250  0.067821    0.9658  0.110189\n",
      "73  0.975000  0.078566    0.9688  0.101259\n",
      "74  0.973036  0.083687    0.9657  0.111733\n",
      "75  0.975000  0.083509    0.9678  0.103073\n",
      "76  0.974464  0.080828    0.9695  0.099173\n",
      "77  0.974821  0.080439    0.9704  0.097034\n",
      "78  0.975714  0.079219    0.9718  0.094510\n",
      "79  0.976607  0.076408    0.9701  0.094826\n",
      "\n",
      "[80 rows x 4 columns]\n",
      "Initialized IDP mechanism 10%\n",
      "Initialized IDP mechanism 15%\n",
      "Initialized IDP mechanism 20%\n",
      "Initialized IDP mechanism 25%\n",
      "Initialized IDP mechanism 30%\n",
      "Initialized IDP mechanism 35%\n",
      "Initialized IDP mechanism 40%\n",
      "Initialized IDP mechanism 45%\n",
      "Initialized IDP mechanism 50%\n",
      "Initialized IDP mechanism 55%\n",
      "Initialized IDP mechanism 60%\n",
      "Initialized IDP mechanism 65%\n",
      "Initialized IDP mechanism 70%\n",
      "Initialized IDP mechanism 75%\n",
      "Initialized IDP mechanism 80%\n",
      "Initialized IDP mechanism 85%\n",
      "Initialized IDP mechanism 90%\n",
      "Initialized IDP mechanism 95%\n",
      "Initialized IDP mechanism 100%\n",
      "     IDP    accu   profile\n",
      "0   0.10  0.6459  harmonic\n",
      "1   0.15  0.6815  harmonic\n",
      "2   0.20  0.6857  harmonic\n",
      "3   0.25  0.7490  harmonic\n",
      "4   0.30  0.8705  harmonic\n",
      "5   0.35  0.8781  harmonic\n",
      "6   0.40  0.9090  harmonic\n",
      "7   0.45  0.9172  harmonic\n",
      "8   0.50  0.9251  harmonic\n",
      "9   0.55  0.9370  harmonic\n",
      "10  0.60  0.9437  harmonic\n",
      "11  0.65  0.9474  harmonic\n",
      "12  0.70  0.9533  harmonic\n",
      "13  0.75  0.9572  harmonic\n",
      "14  0.80  0.9625  harmonic\n",
      "15  0.85  0.9657  harmonic\n",
      "16  0.90  0.9686  harmonic\n",
      "17  0.95  0.9706  harmonic\n",
      "18  1.00  0.9701  harmonic\n",
      "half-exp\n",
      "<tf.Variable 'half-exp3/r1:0' shape=(784,) dtype=float32_ref> is not trainable.\n",
      "<tf.Variable 'half-exp3/r2:0' shape=(100,) dtype=float32_ref> is not trainable.\n",
      "<tf.Variable 'half-exp3/r3:0' shape=(100,) dtype=float32_ref> is not trainable.\n",
      "Initialized.\n",
      "        accu      loss  val_accu  val_loss\n",
      "0   0.736786  0.932808    0.8822  0.413915\n",
      "1   0.886429  0.375261    0.9002  0.328339\n",
      "2   0.913214  0.292973    0.9191  0.274175\n",
      "3   0.917500  0.268380    0.9298  0.233751\n",
      "4   0.928214  0.233850    0.9296  0.233820\n",
      "5   0.938750  0.211489    0.9421  0.190703\n",
      "6   0.935536  0.214643    0.9460  0.174571\n",
      "7   0.947321  0.170898    0.9494  0.167631\n",
      "8   0.951786  0.166044    0.9534  0.147175\n",
      "9   0.945357  0.173059    0.9539  0.149257\n",
      "10  0.946786  0.171677    0.9536  0.149292\n",
      "11  0.957500  0.144340    0.9532  0.156209\n",
      "12  0.963929  0.127733    0.9582  0.132278\n",
      "13  0.961607  0.130269    0.9596  0.134948\n",
      "14  0.962857  0.126948    0.9622  0.122917\n",
      "15  0.959107  0.137019    0.9620  0.122470\n",
      "16  0.962143  0.120894    0.9597  0.132459\n",
      "17  0.962857  0.126793    0.9637  0.115166\n",
      "18  0.961250  0.123413    0.9634  0.121753\n",
      "19  0.964821  0.111237    0.9632  0.118142\n",
      "20  0.964643  0.120268    0.9632  0.120418\n",
      "21  0.969464  0.094744    0.9652  0.110868\n",
      "22  0.972500  0.089349    0.9658  0.106701\n",
      "23  0.973393  0.085312    0.9664  0.109220\n",
      "24  0.970536  0.099235    0.9676  0.102711\n",
      "25  0.972143  0.087522    0.9677  0.105926\n",
      "26  0.970357  0.093257    0.9626  0.118437\n",
      "27  0.968571  0.099711    0.9640  0.112159\n",
      "28  0.971964  0.090590    0.9656  0.118484\n",
      "29  0.966964  0.105425    0.9698  0.100235\n",
      "..       ...       ...       ...       ...\n",
      "50  0.983214  0.049580    0.9708  0.103615\n",
      "51  0.983571  0.045533    0.9732  0.088738\n",
      "52  0.983929  0.055705    0.9728  0.093853\n",
      "53  0.983036  0.054769    0.9692  0.098668\n",
      "54  0.981250  0.054480    0.9732  0.092047\n",
      "55  0.982857  0.055642    0.9683  0.111801\n",
      "56  0.982679  0.056192    0.9740  0.088034\n",
      "57  0.984643  0.048727    0.9701  0.112156\n",
      "58  0.981071  0.061148    0.9716  0.097315\n",
      "59  0.979286  0.062021    0.9705  0.099048\n",
      "60  0.983750  0.045999    0.9693  0.104513\n",
      "61  0.988393  0.037140    0.9725  0.093452\n",
      "62  0.989643  0.034769    0.9721  0.096372\n",
      "63  0.988571  0.036944    0.9717  0.099319\n",
      "64  0.984643  0.047864    0.9714  0.096288\n",
      "65  0.984464  0.047188    0.9697  0.109079\n",
      "66  0.984107  0.047503    0.9723  0.108839\n",
      "67  0.980893  0.054016    0.9732  0.093314\n",
      "68  0.981250  0.057275    0.9732  0.087568\n",
      "69  0.982679  0.054771    0.9744  0.084721\n",
      "70  0.988571  0.035268    0.9758  0.092117\n",
      "71  0.988393  0.032580    0.9762  0.086817\n",
      "72  0.988214  0.033892    0.9747  0.090326\n",
      "73  0.989107  0.033105    0.9738  0.091357\n",
      "74  0.986786  0.037922    0.9733  0.092053\n",
      "75  0.985536  0.043176    0.9719  0.102919\n",
      "76  0.982322  0.048418    0.9707  0.104341\n",
      "77  0.988750  0.035542    0.9731  0.092007\n",
      "78  0.984821  0.040241    0.9729  0.098637\n",
      "79  0.984464  0.045338    0.9742  0.092870\n",
      "\n",
      "[80 rows x 4 columns]\n",
      "Initialized IDP mechanism 10%\n",
      "Initialized IDP mechanism 15%\n",
      "Initialized IDP mechanism 20%\n",
      "Initialized IDP mechanism 25%\n",
      "Initialized IDP mechanism 30%\n",
      "Initialized IDP mechanism 35%\n",
      "Initialized IDP mechanism 40%\n",
      "Initialized IDP mechanism 45%\n",
      "Initialized IDP mechanism 50%\n",
      "Initialized IDP mechanism 55%\n",
      "Initialized IDP mechanism 60%\n",
      "Initialized IDP mechanism 65%\n",
      "Initialized IDP mechanism 70%\n",
      "Initialized IDP mechanism 75%\n",
      "Initialized IDP mechanism 80%\n",
      "Initialized IDP mechanism 85%\n",
      "Initialized IDP mechanism 90%\n",
      "Initialized IDP mechanism 95%\n",
      "Initialized IDP mechanism 100%\n",
      "     IDP    accu   profile\n",
      "0   0.10  0.3025  half-exp\n",
      "1   0.15  0.4302  half-exp\n",
      "2   0.20  0.5450  half-exp\n",
      "3   0.25  0.6552  half-exp\n",
      "4   0.30  0.6930  half-exp\n",
      "5   0.35  0.7494  half-exp\n",
      "6   0.40  0.8587  half-exp\n",
      "7   0.45  0.9295  half-exp\n",
      "8   0.50  0.9691  half-exp\n",
      "9   0.55  0.9739  half-exp\n",
      "10  0.60  0.9742  half-exp\n",
      "11  0.65  0.9742  half-exp\n",
      "12  0.70  0.9742  half-exp\n",
      "13  0.75  0.9742  half-exp\n",
      "14  0.80  0.9742  half-exp\n",
      "15  0.85  0.9742  half-exp\n",
      "16  0.90  0.9742  half-exp\n",
      "17  0.95  0.9742  half-exp\n",
      "18  1.00  0.9742  half-exp\n"
     ]
    }
   ],
   "source": [
    "counter = counter + 1\n",
    "for profile in profile_test:\n",
    "    print(profile)\n",
    "    with tf.variable_scope(profile+str(counter)):\n",
    "        model_test = model(profile=profile)\n",
    "        save_dir = \"~/IDP/output/1_\"\n",
    "        epochs = 80\n",
    "        batch_per_epoch = 200\n",
    "        batch_size = 28\n",
    "        learning_rate = 0.001\n",
    "        config = {'epochs': epochs,\n",
    "                  'batch_per_epoch': batch_per_epoch,\n",
    "                  'batch_size': batch_size,\n",
    "                  'learning_rate': learning_rate,\n",
    "                  'save_dir': save_dir,\n",
    "                  'log_file': save_dir+profile+\"_log.csv\",\n",
    "                  'result_file': save_dir+profile+\"_result.csv\",\n",
    "                  'mnist': mnist}\n",
    "        with tf.Session() as sess:\n",
    "            log = model_test.train(sess=sess,config=config,gamma_trainable=False,verbose=False)\n",
    "            log = pd.DataFrame.from_dict(log)\n",
    "            log.to_csv(config['log_file'],index=None)\n",
    "            print(log)\n",
    "            \n",
    "            true_lab = [np.argmax(ite) for ite in mnist.test.labels]\n",
    "            profile_arr = []\n",
    "            idp_arr = []\n",
    "            accu_arr = []\n",
    "            for idp in np.arange(0.1,1.05,0.05):  \n",
    "                probs = model_test.predict(sess=sess,config=config,idp=idp,scope='i'+str(int(idp*100)))\n",
    "                pred_lab = [np.argmax(ite) for ite in probs[0]]\n",
    "                accu = accuracy_score(y_pred=pred_lab,y_true=true_lab)\n",
    "                profile_arr.append(profile)\n",
    "                idp_arr.append(idp)\n",
    "                accu_arr.append(accu)\n",
    "            log = pd.DataFrame.from_dict({'profile':profile_arr,'IDP':idp_arr,'accu':accu_arr})\n",
    "            log.to_csv(config['result_file'],index=None)\n",
    "            print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
